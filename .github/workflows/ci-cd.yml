name: ML Model CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      deployment_type:
        description: 'Deployment type'
        required: true
        default: 'kserve'
        type: choice
        options:
          - kserve
          - standard

env:
  DOCKER_REGISTRY: docker.io  # Change to your registry (ghcr.io, gcr.io, etc.)
  IMAGE_NAME: ${{ github.repository }}  # or specify custom name
  K8S_NAMESPACE: ml-models

jobs:
  # Job 1: Train the ML Model
  train-model:
    name: Train ML Model
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Train model
        run: |
          python train_model.py

      - name: Verify model files
        run: |
          ls -la model/
          test -f model/iris_model.pkl || exit 1
          test -f model/metadata.pkl || exit 1

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: model/
          retention-days: 30

  # Job 2: Run Tests (if you have tests)
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: train-model

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: model/

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest requests

      - name: Test model loading
        run: |
          python -c "import joblib; model = joblib.load('model/iris_model.pkl'); print('Model loaded successfully')"

      - name: Start Flask app in background
        run: |
          python app.py &
          sleep 5

      - name: Test health endpoint
        run: |
          curl -f http://localhost:5000/health || exit 1

      - name: Test prediction endpoint
        run: |
          curl -X POST http://localhost:5000/predict \
            -H "Content-Type: application/json" \
            -d '{"features": [5.1, 3.5, 1.4, 0.2]}' \
            -f || exit 1

  # Job 3: Build and Push Docker Image
  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}
      image_digest: ${{ steps.build.outputs.digest }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: model/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ secrets.DOCKER_USERNAME }}  # or GHCR_USERNAME for GitHub Container Registry
          password: ${{ secrets.DOCKER_PASSWORD }}  # or GITHUB_TOKEN for GHCR

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

  # Job 4: Deploy to Kubernetes (Standard)
  deploy-standard:
    name: Deploy to Kubernetes (Standard)
    runs-on: ubuntu-latest
    needs: build-and-push
    if: |
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.deployment_type == 'standard')
    environment:
      name: production-standard
      url: http://ml-model.local

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      - name: Update image in deployment
        run: |
          sed -i "s|image: ml-model:latest|image: ${{ needs.build-and-push.outputs.image_tag }}|g" k8s/deployment.yaml

      - name: Deploy to Kubernetes
        run: |
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/hpa.yaml

      - name: Wait for rollout
        run: |
          kubectl rollout status deployment/ml-model-deployment --timeout=5m

      - name: Verify deployment
        run: |
          kubectl get deployments
          kubectl get pods
          kubectl get services

      - name: Run smoke tests
        run: |
          kubectl run test-pod --image=curlimages/curl --rm -i --restart=Never -- \
            curl -f http://ml-model-service/health

  # Job 5: Deploy to Kubernetes with KServe
  deploy-kserve:
    name: Deploy to Kubernetes (KServe)
    runs-on: ubuntu-latest
    needs: build-and-push
    if: |
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.deployment_type == 'kserve')
    environment:
      name: production-kserve
      url: http://iris-model.ml-models.example.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      - name: Create namespace if not exists
        run: |
          kubectl create namespace ${{ env.K8S_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Update image in InferenceService
        run: |
          sed -i "s|image: ml-model:latest.*|image: ${{ needs.build-and-push.outputs.image_tag }}|g" k8s/kserve-inferenceservice.yaml

      - name: Deploy InferenceService
        run: |
          kubectl apply -f k8s/kserve-inferenceservice.yaml -n ${{ env.K8S_NAMESPACE }}

      - name: Wait for InferenceService to be ready
        run: |
          timeout=300
          elapsed=0
          while [ $elapsed -lt $timeout ]; do
            status=$(kubectl get inferenceservice iris-model -n ${{ env.K8S_NAMESPACE }} -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "False")
            if [ "$status" = "True" ]; then
              echo "InferenceService is ready!"
              exit 0
            fi
            echo "Waiting for InferenceService to be ready... ($elapsed/$timeout seconds)"
            sleep 10
            elapsed=$((elapsed + 10))
          done
          echo "Timeout waiting for InferenceService"
          kubectl describe inferenceservice iris-model -n ${{ env.K8S_NAMESPACE }}
          exit 1

      - name: Get InferenceService details
        run: |
          kubectl get inferenceservice iris-model -n ${{ env.K8S_NAMESPACE }}
          kubectl get pods -n ${{ env.K8S_NAMESPACE }}
          kubectl describe inferenceservice iris-model -n ${{ env.K8S_NAMESPACE }}

      - name: Run smoke tests
        run: |
          # Get the service URL
          SERVICE_NAME=$(kubectl get inferenceservice iris-model -n ${{ env.K8S_NAMESPACE }} -o jsonpath='{.status.components.predictor.url}')
          echo "Service URL: $SERVICE_NAME"

          # Test health endpoint
          kubectl run test-pod --image=curlimages/curl --rm -i --restart=Never -n ${{ env.K8S_NAMESPACE }} -- \
            curl -f $SERVICE_NAME/health || echo "Health check returned non-zero, but continuing..."

  # Job 6: Notify on completion
  notify:
    name: Notify Deployment Status
    runs-on: ubuntu-latest
    needs: [deploy-standard, deploy-kserve]
    if: always()

    steps:
      - name: Send notification
        run: |
          echo "Deployment completed!"
          echo "Standard K8s: ${{ needs.deploy-standard.result }}"
          echo "KServe: ${{ needs.deploy-kserve.result }}"
          # Add Slack/Discord/Email notification here if needed
